{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dephinate/ASU/DL/MedicalChatBot/research\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dephinate/ASU/DL/MedicalChatBot\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-box\n",
    "# !pip install ensure\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medicalChatBot.config.configurations import ConfigurationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-11 19:24:42,057,INFO,common,created directory at: artifacts]\n"
     ]
    }
   ],
   "source": [
    "configurationManager = ConfigurationManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_config = configurationManager.get_dataloader_config()\n",
    "datasplitter_config = configurationManager.get_datasplitter_config()\n",
    "vectorization_config =  configurationManager.get_vectorization_config()\n",
    "model_config = configurationManager.get_model_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaderConfig(data_path='artifacts/data', file_types='*.pdf')\n",
      "SplitterConfig(chunk_size=500, chunk_overlap=50)\n",
      "VectorizationConfig(encoder_platform='HuggingFace', encoder_name='sentence-transformers/all-MiniLM-L6-v2', model_name='sentence-transformers/all-MiniLM-L6-v2', index_name='medical-chatbot', namespace='medicalChatBot', num_of_documnets=3)\n",
      "ModelConfig(implementation='LlamaCpp', model_path='artifacts/model/llama-2-7b-chat.Q5_K_M.gguf', model_type='llama', n_gpu_layers=32, n_batch=512, n_ctx=1024, f16_kv=True, temperature=0.8, max_new_tokens=512)\n"
     ]
    }
   ],
   "source": [
    "print(dataloader_config)\n",
    "print(datasplitter_config)\n",
    "print(vectorization_config)\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader\n",
    "import pypdf\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from medicalChatBot.entity  import DataLoaderConfig\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self,\n",
    "                 config : DataLoaderConfig)->None :\n",
    "        self.config = config\n",
    "\n",
    "    # Extract data from the pdf\n",
    "    def load_pdf(self):\n",
    "        loader = DirectoryLoader(   # To load all pdfs from a directory\n",
    "            path=self.config.data_path,\n",
    "            glob=self.config.file_types,\n",
    "            loader_cls=PyPDFLoader,\n",
    "            show_progress=True\n",
    "        )\n",
    "        documents = loader.load()\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = DataLoader(config=dataloader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:13<00:00, 13.20s/it]\n"
     ]
    }
   ],
   "source": [
    "extracted_data = dataLoader.load_pdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from medicalChatBot.config.configurations import ConfigurationManager\n",
    "from medicalChatBot.entity  import SplitterConfig\n",
    "\n",
    "class Splitter:\n",
    "    def __init__(self,\n",
    "                 config:SplitterConfig) -> None:\n",
    "        self.config = config\n",
    "\n",
    "    # function to impement recursive text splitting \n",
    "    def split_recursive(self, extracted_data:None):\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size = self.config.chunk_size  , chunk_overlap = self.config.chunk_overlap, separators=['\\n\\n', '\\n', '.', ','])\n",
    "        chunks = splitter.split_documents(extracted_data)\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = Splitter(config=datasplitter_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = splitter.split_recursive(extracted_data=extracted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from medicalChatBot.entity import VectorizationConfig\n",
    "from medicalChatBot.utils.common import load_env\n",
    "\n",
    "\n",
    "\n",
    "class Vectorizer:\n",
    "    def __init__(self,\n",
    "                 config : VectorizationConfig) -> None:\n",
    "        self.config = config\n",
    "\n",
    "    def download_embeddings_from_huggingface(self,model_name = None):\n",
    "        model_name = model_name or self.config.model_name\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "        return embeddings\n",
    "    \n",
    "    def create_pinecone_instance(self,env_file_path = None):\n",
    "        pc = Pinecone(\n",
    "            api_key = load_env(env_file_path=env_file_path),\n",
    "        )\n",
    "        return pc\n",
    "    \n",
    "    def check_pinecone_index_status(self,db_instance, index_name = None):\n",
    "        index_name = index_name or self.config.index_name\n",
    "        index = db_instance.Index(index_name)\n",
    "        index.describe_index_stats()\n",
    "\n",
    "    def create_pinecone_vectorstore_instance(self,index=None,namespace=None,index_name=None,embeddings=None):\n",
    "        index_name = index or self.config.index_name\n",
    "        namespace = namespace or self.config.namespace\n",
    "        \n",
    "        vectorstore = PineconeVectorStore(\n",
    "        index=index,\n",
    "        embeddings=embeddings,\n",
    "        namespace=namespace,\n",
    "        index_name=index_name\n",
    "        )\n",
    "        return vectorstore\n",
    "    \n",
    "    def clean_pinecone_db(self, db_instance,namespace):\n",
    "        db_instance.delete(delete_all=True,namespace=namespace)\n",
    "\n",
    "    def add_records_pinecone_db(self,vectorstore_instance, chunks):\n",
    "        vectorstore_instance.add_texts(texts=[t.page_content for t in chunks])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"abc\"\n",
    "model_name_b = \"pqrs\"\n",
    "model_name or model_name_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicalChatBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
