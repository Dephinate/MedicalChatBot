{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dephinate/ASU/DL/MedicalChatBot/research\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dephinate/ASU/DL/MedicalChatBot\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install python-box\n",
    "# !pip install ensure\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ce80aa7c-c98e-467c-a100-b4b7e6a07c05'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv('PINECONE_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from medicalChatBot.config.configurations import ConfigurationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-04-12 18:39:15,491,INFO,common,created directory at: artifacts]\n"
     ]
    }
   ],
   "source": [
    "configurationManager = ConfigurationManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_config = configurationManager.get_dataloader_config()\n",
    "datasplitter_config = configurationManager.get_datasplitter_config()\n",
    "vectorization_config =  configurationManager.get_vectorization_config()\n",
    "model_config = configurationManager.get_model_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataLoaderConfig(data_path='artifacts/data', file_types='*.pdf')\n",
      "SplitterConfig(chunk_size=500, chunk_overlap=50)\n",
      "VectorizationConfig(encoder_platform='HuggingFace', encoder_name='sentence-transformers/all-MiniLM-L6-v2', model_name='sentence-transformers/all-MiniLM-L6-v2', index_name='medical-chatbot', namespace='medicalChatBot', num_of_documnets=3)\n",
      "ModelConfig(implementation='LlamaCpp', model_path='artifacts/model/llama-2-7b-chat.Q5_K_M.gguf', model_type='llama', n_gpu_layers=32, n_batch=512, n_ctx=1024, f16_kv=True, temperature=0.8, max_new_tokens=512)\n"
     ]
    }
   ],
   "source": [
    "print(dataloader_config)\n",
    "print(datasplitter_config)\n",
    "print(vectorization_config)\n",
    "print(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loader\n",
    "import pypdf\n",
    "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from medicalChatBot.entity  import DataLoaderConfig\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self,\n",
    "                 config : DataLoaderConfig)->None :\n",
    "        self.config = config\n",
    "\n",
    "    # Extract data from the pdf\n",
    "    def load_pdf(self):\n",
    "        loader = DirectoryLoader(   # To load all pdfs from a directory\n",
    "            path=self.config.data_path,\n",
    "            glob=self.config.file_types,\n",
    "            loader_cls=PyPDFLoader,\n",
    "            show_progress=True\n",
    "        )\n",
    "        documents = loader.load()\n",
    "        return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataLoader = DataLoader(config=dataloader_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:08<00:00,  8.49s/it]\n"
     ]
    }
   ],
   "source": [
    "extracted_data = dataLoader.load_pdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from medicalChatBot.config.configurations import ConfigurationManager\n",
    "from medicalChatBot.entity  import SplitterConfig\n",
    "\n",
    "class Splitter:\n",
    "    def __init__(self,\n",
    "                 config:SplitterConfig) -> None:\n",
    "        self.config = config\n",
    "\n",
    "    # function to impement recursive text splitting \n",
    "    def split_recursive(self, extracted_data:None):\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size = self.config.chunk_size  , chunk_overlap = self.config.chunk_overlap, separators=['\\n\\n', '\\n', '.', ','])\n",
    "        chunks = splitter.split_documents(extracted_data)\n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = Splitter(config=datasplitter_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = splitter.split_recursive(extracted_data=extracted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pinecone import Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from medicalChatBot.entity import VectorizationConfig\n",
    "from medicalChatBot.utils.common import load_env\n",
    "\n",
    "\n",
    "\n",
    "class Vectorizer:\n",
    "    def __init__(self,\n",
    "                 config : VectorizationConfig = None) -> None:\n",
    "        self.config = config\n",
    "\n",
    "    def download_embeddings_from_huggingface(self,model_name:str = None):\n",
    "        model_name = model_name or self.config.encoder_name\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
    "        return embeddings\n",
    "    \n",
    "    def create_pinecone_instance(self,env_file_path:str = None):\n",
    "        load_env(env_file_path=env_file_path)\n",
    "        pc = Pinecone(\n",
    "            api_key = f\"{os.getenv('PINECONE_API_KEY')}\"\n",
    "        )\n",
    "        return pc\n",
    "    \n",
    "    def check_pinecone_index_status(self,db_instance, index_name = None):\n",
    "        index_name = index_name or self.config.index_name\n",
    "        index = db_instance.Index(index_name)\n",
    "        return index.describe_index_stats()\n",
    "\n",
    "    def create_pinecone_vectorstore_instance(self,db_instance=None,namespace=None,index_name=None,embeddings=None):\n",
    "        index_name = index_name or self.config.index_name\n",
    "        namespace = namespace or self.config.namespace\n",
    "        \n",
    "        vectorstore = PineconeVectorStore(\n",
    "        index=db_instance.Index(index_name),\n",
    "        embedding=embeddings,\n",
    "        namespace=namespace,\n",
    "        index_name=index_name\n",
    "        )\n",
    "        return vectorstore\n",
    "    \n",
    "    def clean_pinecone_db(self, db_instance,index_name:str=None,namespace:str=None):\n",
    "        index_name = index_name or self.config.index_name\n",
    "        namespace = namespace or self.config.namespace\n",
    "        db_instance.Index(index_name).delete(delete_all=True,namespace=namespace)\n",
    "\n",
    "    def add_records_pinecone_db(self,vectorstore_instance, chunks):\n",
    "        vectorstore_instance.add_texts(texts=[t.page_content for t in chunks])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorizationConfig(encoder_platform='HuggingFace', encoder_name='sentence-transformers/all-MiniLM-L6-v2', model_name='sentence-transformers/all-MiniLM-L6-v2', index_name='medical-chatbot', namespace='medicalChatBot', num_of_documnets=3)\n"
     ]
    }
   ],
   "source": [
    "# initialize Vectorizer\n",
    "print(vectorization_config)\n",
    "vectorizer = Vectorizer(config=vectorization_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings\n",
    "embeddings = vectorizer.download_embeddings_from_huggingface()\n",
    "# Instantiate vectordb\n",
    "pc = vectorizer.create_pinecone_instance(env_file_path=\".env\")\n",
    "index_list = pc.list_indexes()\n",
    "index_status = vectorizer.check_pinecone_index_status(db_instance=pc)\n",
    "\n",
    "print(\"embeddings :\",embeddings)\n",
    "print(\"\\nindex_list:\", index_list)\n",
    "print(\"\\nindex_status :\",index_status)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Nancy J. Nordenson\\nAcid reflux seeHeartburn\\nAcidosis seeRespiratory acidosis; Renal\\ntubular acidosis; Metabolic acidosis\\nAcne\\nDefinition\\nAcne is a common skin disease characterized by\\npimples on the face, chest, and back. It occurs when thepores of the skin become clogged with oil, dead skincells, and bacteria.\\nDescription\\nAcne vulgaris, the medical term for common acne, is'),\n",
       " Document(page_content='The goal of treating moderate acne is to decrease\\ninflammation and prevent new comedone formation. Oneeffective treatment is topical tretinoin along with a topical\\nGALE ENCYCLOPEDIA OF MEDICINE 2 25Acne\\nAcne vulgaris affecting a woman’s face. Acne is the general\\nname given to a skin disorder in which the sebaceousglands become inflamed. (Photograph by Biophoto Associ-\\nates, Photo Researchers, Inc. Reproduced by permission.)GEM - 0001 to 0432 - A  10/22/03 1:41 PM  Page 25'),\n",
       " Document(page_content='ent purposes. For example, lotions, soaps, gels, andcreams containing benzoyl peroxide or tretinoin may beused to clear up mild to moderately severe acne.Isotretinoin (Accutane) is prescribed only for verysevere, disfiguring acne.\\nAcne is a skin condition that occurs when pores or')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create vectorstore and test\n",
    "vector_store = vectorizer.create_pinecone_vectorstore_instance(db_instance= pc,embeddings=embeddings)\n",
    "\n",
    "query = \"What is ACne ?\"\n",
    "\n",
    "chunks_retrieved = vector_store.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")\n",
    "chunks_retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cleanup and check status\n",
    "vectorizer.clean_pinecone_db(db_instance=pc)\n",
    "\n",
    "index_status = vectorizer.check_pinecone_index_status(db_instance=pc)\n",
    "index_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing db loading\n",
    "vectorizer.add_records_pinecone_db(vectorstore_instance=vector_store,chunks=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 384,\n",
       " 'index_fullness': 0.07093,\n",
       " 'namespaces': {'medicalChatBot': {'vector_count': 7093}},\n",
       " 'total_vector_count': 7093}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test status\n",
    "index_status = vectorizer.check_pinecone_index_status(db_instance=pc)\n",
    "index_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers\n",
    "from langchain_community.llms import LlamaCpp\n",
    "from medicalChatBot.entity import ModelConfig\n",
    "\n",
    "class LoadModel:\n",
    "    def __init__(self,\n",
    "                 config:ModelConfig = None) -> None:\n",
    "        self.config = config\n",
    "\n",
    "    def load_model_from_ctransformers(self, model_path = None, model_type=None,max_new_tokens=None,temperature=None):\n",
    "        model_path = model_path or self.config.model_path\n",
    "        model_type = model_type or self.config.model_type\n",
    "        max_new_tokens = max_new_tokens or self.config.max_new_tokens\n",
    "        temperature = temperature or self.config.temperature\n",
    "\n",
    "        llm=CTransformers(model=model_path,\n",
    "                        model_type=model_type,\n",
    "                        config={'max_new_tokens':max_new_tokens,\n",
    "                                'temperature':temperature})\n",
    "        \n",
    "        return llm\n",
    "    \n",
    "    def load_model_from_llamacpp(self,model_path:str=None, n_gpu_layers:int=None, n_batch:int=None, n_ctx:int=None, f16_kv:bool=None, temperature:int=None):\n",
    "        model_path = model_path or self.config.model_path \n",
    "        n_gpu_layers = n_gpu_layers or self.config.n_gpu_layers \n",
    "        n_batch = n_batch or self.config.n_batch\n",
    "        n_ctx = n_ctx or self.config.n_ctx\n",
    "        f16_kv = f16_kv or self.config.f16_kv\n",
    "        temperature = temperature or self.config.temperature\n",
    "        lcpp_llm = None\n",
    "        lcpp_llm = LlamaCpp(\n",
    "            model_path=model_path,\n",
    "            n_gpu_layers=n_gpu_layers,\n",
    "            n_batch=n_batch,\n",
    "            n_ctx=n_ctx,\n",
    "            f16_kv=f16_kv, \n",
    "            temperature = temperature\n",
    "            )\n",
    "        return lcpp_llm\n",
    "    \n",
    "    def load_model(self):\n",
    "        if 'ctransformers' in (self.config.implementation).lower:\n",
    "            llm = self.load_model_from_llamacpp()\n",
    "        if 'llama' or 'llamacpp' in (self.config.implementation).lower:\n",
    "            llm = self.load_model_from_llamacpp()\n",
    "        return llm        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medicalChatBot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
