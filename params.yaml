model_params:
# LlamaCpp
  n_gpu_layers: 32
  n_batch: 512
  n_ctx: 1024
  f16_kv: True 
  temperature: 0.8

# CTransformers  
  model_type: llama
  max_new_tokens: 512
